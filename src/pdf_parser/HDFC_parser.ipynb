{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDFC parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tables = camelot.read_pdf('/content/drive/MyDrive/SampleBankPdfs/AC/Hdfc-AC-Statement-p3.pdf', flavor='stream', pages=\"all\", table_areas=['20,615,640,65'], columns=['60,281.1025000000001,351.1025,421.1025,500,571.446'])\n",
    "\n",
    "print(f\"Number of tables found: {len(tables)}\")\n",
    "\n",
    "\n",
    "def fix_narration(fixed_tables_len, data):\n",
    "  df = pd.DataFrame(data)\n",
    "  # print(df)\n",
    "\n",
    "  # Initialize an empty list to hold the fixed rows\n",
    "  fixed_rows = []\n",
    "\n",
    "  # Variables to hold data while combining rows\n",
    "  current_row = {}\n",
    "  current_row[1] = ''\n",
    "\n",
    "  # Iterate over DataFrame rows\n",
    "  for index, row in df.iterrows():\n",
    "      # Check if current row is a continuation of previous page's empty 'Date' column\n",
    "      if index == 0 and (pd.isna(row[0]) or row[0] == '') and fixed_tables_len > 0:\n",
    "          # Append narration to current row if it is a continuation\n",
    "          fixed_tables[fixed_tables_len-1].iat[-1,0] += row[1]\n",
    "      # Check if current row is a continuation (empty 'Date' column)\n",
    "      elif pd.isna(row[0]) or row[0] == '':\n",
    "          # Append narration to current row if it is a continuation\n",
    "          current_row[1] += row[1]\n",
    "      else:\n",
    "          # If not a continuation, save the current_row and start a new one\n",
    "          if current_row:\n",
    "              fixed_rows.append(current_row)\n",
    "          current_row = row.to_dict()\n",
    "\n",
    "  # Append the last accumulated row\n",
    "  if current_row:\n",
    "      fixed_rows.append(current_row)\n",
    "\n",
    "  # Convert fixed_rows back to DataFrame\n",
    "  return pd.DataFrame(fixed_rows)\n",
    "\n",
    "\n",
    "# Initialize a list to store the fixed DataFrames\n",
    "fixed_tables = []\n",
    "\n",
    "for table in tables:\n",
    "  # camelot.plot(table, kind='contour').show()\n",
    "  # camelot.plot(table, kind='grid').show()\n",
    "  fixed_tables.append(fix_narration(len(fixed_tables), table.df)) # Append the fixed DataFrame to the list\n",
    "\n",
    "# Concatenate all the fixed DataFrames into a single DataFrame\n",
    "df = pd.concat(fixed_tables, ignore_index=True)\n",
    "\n",
    "\n",
    "# Remove 'STATEMENT SUMMARY' from the last narration\n",
    "last_row = df.iloc[-1]\n",
    "if 'STATEMENT SUMMARY' in last_row[1]:\n",
    "    df.at[df.index[-1], 1] = last_row[1].split('STATEMENT SUMMARY')[0].strip()\n",
    "\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df.replace('', np.nan, inplace=True)\n",
    "\n",
    "# remove empty rows\n",
    "df = df.dropna(how='all').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Set the first row as the new column names\n",
    "df.columns = df.iloc[0]\n",
    "\n",
    "# Drop the first row\n",
    "df = df[1:].reset_index(drop=True)\n",
    "display(df)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/content/drive/MyDrive/SampleBankPdfs/outputs/hdfc_camelot_stream.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to JSON\n",
    "\n",
    "df1 = df\n",
    "\n",
    "df1['Date'] = pd.to_datetime(df1['Date'], format='%d/%m/%y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# 0. Add a new column \"isDebit\" instead of \"transactionType\"\n",
    "df1['isDebit'] = df1['Withdrawal Amt.'].apply(lambda x: False if pd.isna(x) else True)\n",
    "\n",
    "# 1. Add a new column \"transactionType\"\n",
    "df1['transactionType'] = df1['Withdrawal Amt.'].apply(lambda x: 'income' if pd.isna(x) else 'expense')\n",
    "\n",
    "# 2. Create a new column \"amount\"\n",
    "# df1['amount'] = df1.apply(lambda row: row['Withdrawal Amt.'] if row['transactionType'] == 'expense' else row['Deposit Amt.'], axis=1)\n",
    "df1['amount'] = df1.apply(lambda row: row['Withdrawal Amt.'] if row['isDebit'] else row['Deposit Amt.'], axis=1)\n",
    "\n",
    "# Convert the \"amount\" column to numeric (handle commas and convert to float)\n",
    "df1['amount'] = df1['amount'].replace(',', '', regex=True).astype(float)\n",
    "df1['Closing Balance'] = df1['Closing Balance'].replace(',', '', regex=True).astype(float)\n",
    "\n",
    "# 3. Remove the columns \"Withdrawal Amt.\" and \"Deposit Amt.\"\n",
    "df1.drop(columns=['Withdrawal Amt.', 'Deposit Amt.', 'Value Dt', 'Chq./Ref.No.'], inplace=True)\n",
    "\n",
    "# 4. Rename the columns\n",
    "df1.rename(columns={'Date': 'date', 'Narration': 'description', 'Closing Balance':'balance'}, inplace=True)\n",
    "\n",
    "\n",
    "# HOW TO IDENTIFY NOTES\n",
    "# Paid to ABC\n",
    "# Received from ABC\n",
    "\n",
    "\n",
    "# print(df1)\n",
    "\n",
    "\n",
    "data_dict = df1.to_dict(orient='records')\n",
    "json_data = json.dumps(data_dict, ensure_ascii=False).replace('\\\\/', '/').replace('NaN', 'null')\n",
    "\n",
    "print(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel",
   "language": "python",
   "name": "kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
